<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<groupId>org.nita</groupId>
	<artifactId>sparkexample</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<name>${project.artifactId}</name>
	<description>My wonderfull scala app</description>
	<inceptionYear>2010</inceptionYear>
	<licenses>
		<license>
			<name>My License</name>
			<url>http://....</url>
			<distribution>repo</distribution>
		</license>
	</licenses>

	<properties>
		<maven.compiler.source>1.7</maven.compiler.source>
		<maven.compiler.target>1.7</maven.compiler.target>
		<encoding>UTF-8</encoding>
		<scala.tools.version>2.10</scala.tools.version>
		<scala.version>2.11.7</scala.version>
		<platform.name>${os.name}-${os.arch}</platform.name>
	</properties>
	<profiles>
		<profile>
			<id>hbase-hadoop1</id>
			<activation>
				<property>
					<name>!hbase.profile</name>
				</property>
			</activation>
			<properties>
				<hbase.version>0.98.7-hadoop1</hbase.version>
				<scala.binary.version>2.11</scala.binary.version>
				<jetty.version>8.1.14.v20131031</jetty.version>
				<commons.math3.version>3.1.1</commons.math3.version>
			</properties>
		</profile>
	</profiles>
	<dependencies>
		<dependency>
			<groupId>com.typesafe.scala-logging</groupId>
			<artifactId>scala-logging-slf4j_2.11</artifactId>
			<version>2.1.2</version>
		</dependency>
		<!-- spark -->
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>${scala.version}</version>
		</dependency>
		<!-- Promote Guava to compile scope in this module so it's included while 
			shading. -->
		<!-- <dependency> <groupId>com.google.guava</groupId> <artifactId>guava</artifactId> 
			<scope>compile</scope> </dependency> -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.binary.version}</artifactId>
			<version>1.5.0</version>
			<exclusions>
				<exclusion>
					<groupId>com.typesafe.akka</groupId>
					<artifactId>akka-remote_2.11</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>com.typesafe.akka</groupId>
			<artifactId>akka-actor_2.11</artifactId>
			<version>2.3.3</version>
		</dependency>
		<dependency>
			<groupId>com.typesafe.akka</groupId>
			<artifactId>akka-remote_2.11</artifactId>
			<version>2.3.10</version>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming_${scala.binary.version}</artifactId>
			<version>1.5.0</version>

		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_${scala.binary.version}</artifactId>
			<version>1.5.0</version>

		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-bagel_${scala.binary.version}</artifactId>
			<version>1.5.0</version>

		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-hive_${scala.binary.version}</artifactId>
			<version>1.5.0</version>

		</dependency>


		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-twitter_${scala.binary.version}</artifactId>
			<version>1.5.0</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-flume_${scala.binary.version}</artifactId>
			<version>1.5.0</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-mqtt_${scala.binary.version}</artifactId>
			<version>1.5.0</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-zeromq_${scala.binary.version}</artifactId>
			<version>1.5.0</version>
			<exclusions>
				<exclusion>
					<groupId>org.spark-project.zeromq</groupId>
					<artifactId>zeromq-scala-binding_2.11</artifactId>

				</exclusion>
			</exclusions>
		</dependency>

		<!-- <dependency> <groupId>org.eclipse.jetty</groupId> <artifactId>jetty-server</artifactId> 
			<version>8.1.14.v20131031</version> </dependency> -->
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-testing-util</artifactId>
			<version>${hbase.version}</version>
			<exclusions>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.jruby</groupId>
					<artifactId>jruby-complete</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-protocol</artifactId>
			<version>${hbase.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-common</artifactId>
			<version>${hbase.version}</version>
			<exclusions>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-client</artifactId>
			<version>${hbase.version}</version>
			<exclusions>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>io.netty</groupId>
					<artifactId>netty</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-server</artifactId>
			<version>${hbase.version}</version>
			<exclusions>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-client</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-mapreduce-client-jobclient</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-mapreduce-client-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-auth</artifactId>
				</exclusion>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-hdfs</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-hadoop1-compat</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.commons</groupId>
					<artifactId>commons-math</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.slf4j</groupId>
					<artifactId>slf4j-api</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-server</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-json</artifactId>
				</exclusion>
				<exclusion>
					<!-- hbase uses v2.4, which is better, but ... -->
					<groupId>commons-io</groupId>
					<artifactId>commons-io</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-hadoop-compat</artifactId>
			<version>${hbase.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-hadoop-compat</artifactId>
			<version>${hbase.version}</version>
			<type>test-jar</type>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.commons</groupId>
			<artifactId>commons-math3</artifactId>
			<version>3.1.1</version>
		</dependency>
		<dependency>
			<groupId>com.twitter</groupId>
			<artifactId>algebird-core_${scala.binary.version}</artifactId>
			<version>0.11.0</version>
		</dependency>
		<dependency>
			<groupId>org.scalatest</groupId>
			<artifactId>scalatest_${scala.binary.version}</artifactId>
			<version>3.0.0-M10</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.scalacheck</groupId>
			<artifactId>scalacheck_${scala.binary.version}</artifactId>
			<version>1.12.5</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.cassandra</groupId>
			<artifactId>cassandra-all</artifactId>
			<version>1.2.6</version>
			<exclusions>
				<exclusion>
					<groupId>com.google.guava</groupId>
					<artifactId>guava</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.googlecode.concurrentlinkedhashmap</groupId>
					<artifactId>concurrentlinkedhashmap-lru</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.ning</groupId>
					<artifactId>compress-lzf</artifactId>
				</exclusion>
				<exclusion>
					<groupId>io.netty</groupId>
					<artifactId>netty</artifactId>
				</exclusion>
				<exclusion>
					<groupId>jline</groupId>
					<artifactId>jline</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.cassandra.deps</groupId>
					<artifactId>avro</artifactId>
				</exclusion>
			</exclusions>
		</dependency>

<dependency>
    <groupId>com.github.scopt</groupId>
    <artifactId>scopt_2.10</artifactId>
    <version>3.2.0</version>
</dependency>

	</dependencies>

	<build>
		<sourceDirectory>src/main/scala</sourceDirectory>

		<plugins>
			<plugin>
				<!-- see http://davidb.github.com/scala-maven-plugin -->
				<groupId>net.alchim31.maven</groupId>
				<artifactId>scala-maven-plugin</artifactId>
				<version>3.1.3</version>
				<executions>
					<execution>
						<goals>
							<goal>compile</goal>
							<goal>testCompile</goal>
						</goals>
						<configuration>
							<args>
								<arg>-make:transitive</arg>
								<arg>-dependencyfile</arg>
								<arg>${project.build.directory}/.scala_dependencies</arg>
							</args>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<!-- for google protocol -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<configuration>
					<source>1.7</source>
					<target>1.7</target>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<version>2.0</version>
				<executions>
					<execution>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
						<configuration>
							<shadedArtifactAttached>true</shadedArtifactAttached>
							<shadedClassifierName>allinone</shadedClassifierName>
							<artifactSet>
								<includes>
									<include>*:*</include>
								</includes>
							</artifactSet>
							<transformers>
								<transformer
									implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
									<manifestEntries>
										<Main-Class>org.nita.sparkExample.HdfsWordCount</Main-Class>
									</manifestEntries>
								</transformer>
								<transformer
									implementation="org.apache.maven.plugins.shade.resource.DontIncludeResourceTransformer">
									<resource>log4j.properties</resource>
								</transformer>
							</transformers>
						</configuration>
					</execution>
				</executions>
			</plugin>

			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<version>2.13</version>
				<configuration>
					<useFile>false</useFile>
					<disableXmlReport>true</disableXmlReport>
					<includes>
						<include>**/*Test.*</include>
						<include>**/*Suite.*</include>
					</includes>
				</configuration>
			</plugin>
		</plugins>
	</build>


</project>
